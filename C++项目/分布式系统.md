# Lecture 01 - Introduction

分布式系统的核心是通过网络来协调，共同完成一致任务的一些计算机。



Q1：为什么需要分布式系统？

- 人们需要获得更高的计算性能。（大量的计算机意味着）大量的并行运算，大量CPU、大量内存、以及大量磁盘在并行的运行。
- 另一个人们构建分布式系统的原因是，它可以提供容错（tolerate faults）。比如两台计算机运行完全相同的任务，其中一台发生故障，可以切换到另一台。
- 第三个原因是，一些问题天然在空间上是分布的。例如银行转账，我们假设银行A在纽约有一台服务器，银行B在伦敦有一台服务器，这就需要一种两者之间协调的方法。所以，有一些天然的原因导致系统是物理分布的。
- 最后一个原因是，人们构建分布式系统来达成一些安全的目标。比如有一些代码并不被信任，但是你又需要和它进行交互，这些代码不会立即表现的恶意或者出现bug。你不会想要信任这些代码，所以你或许想要将代码分散在多处运行，这样你的代码在另一台计算机运行，我的代码在我的计算机上运行，我们通过一些特定的网络协议通信。所以，我们可能会担心安全问题，我们把系统分成多个的计算机，这样可以限制出错域。



Q2：分布式系统存在哪些问题？

- 因为系统中存在很多部分，这些部分又在并发执行，你会遇到并发编程和各种复杂交互所带来的问题，以及时间依赖的问题（比如同步，异步）。这让分布式系统变得很难。
- 另一个导致分布式系统很难的原因是，分布式系统有多个组成部分，再加上计算机网络，你会会遇到一些意想不到的故障。如果你只有一台计算机，那么它通常要么是工作，要么是故障或者没电，总的来说，要么是在工作，要么是没有工作。而由多台计算机组成的分布式系统，可能会有一部分组件在工作，而另一部分组件停止运行，或者这些计算机都在正常运行，但是网络中断了或者不稳定。所以，局部错误也是分布式系统很难的原因。
- 最后一个导致分布式系统很难的原因是，人们设计分布式系统的根本原因通常是为了获得更高的性能，比如说一千台计算机或者一千个磁盘臂达到的性能。但是实际上一千台机器到底有多少性能是一个棘手的问题，这里有很多难点。所以通常需要倍加小心地设计才能让系统实际达到你期望的性能。









## MapReduce：大型集群上的简化数据处理



大型集群：多台服务器组成的协同工作系统。该框架的核心作用是在这类大型集群上高效完成海量数据的简化处理任务。



MapReduce是一种用于处理和生成大规模数据集的编程模型。该模型能自动实现并行化。

核心函数逻辑：

`map函数`：接受一个输入键值，处理后生成一组中间键值对

`reduce函数`：合并所有与同一“中间键”关联的“中间值”，完成数据的合并



**Question**

重点关注设计动机：Google 为什么要提出 MapReduce？它要解决当时的什么痛点？

理解核心流程：Map 阶段做了什么？Reduce 阶段做了什么？Shuffle（数据洗牌）在中间起了什么作用？

思考设计亮点：它是如何解决 “分布式容错”“数据本地化（减少网络传输）”“负载均衡” 这些问题的？

关联技术演变：现在的 Spark、Flink 相比 MapReduce，做了哪些改进？为什么要做这些改进？



分布式数据处理



1. 并行化运算：如何将一个大规模计算任务拆分成多个子任务，分配给集群中的多个节点同时执行，以提高效率？这需要解决任务拆分规则、节点负载均衡等问题。

2. 数据分布：海量数据无法存放在单台机器上，必须分布在集群的多台设备中。如何合理划分数据、让计算节点就近访问数据（减少网络传输）、处理数据分片与计算任务的匹配？

3. 故障处理（handle failures）：在由成百上千台机器组成的大型集群中，硬件故障（如节点宕机、磁盘损坏）或软件异常是常态。如何检测故障、重试失败的任务、保证数据一致性，避免整个计算因局部故障而失败？这需要复杂的容错机制。