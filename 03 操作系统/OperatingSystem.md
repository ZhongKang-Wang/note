# 20250701

Q：进程与程序的区别？

程序：是指令的集合，是静态的；

进程：是程序在处理机上的一次执行过程，动态地产生、执行，然后消亡。

- 一个程序可以由多个进程组成
- 进程具有
  - 独立性：进程是一个相对完整的资源分配单位
  - 异步性：每个进程按照各自独立的、不可预知的速度向前推进。



# 一、硬件结构

## 1.1 CPU 是如何执行程序的?

Question

1. a = 1 + 2 这条代码是怎么被 CPU 执行的？

2. 32 位和 64 位软件的区别？
   - 32 位的操作系统可以运行在 64 位的电脑上吗？
   - 64 位的操作系统可以运行在 32 位的电脑上吗？
   -  如果不行，原因是什么？


> 32 位可以运行在 64 位的电脑上，需要一套兼容机制；64位不可以

1. 64 位相比 32 位 CPU 的优势在哪？

> 64 位 CPU 可以一次计算超过 32 位的数，而32位的CPU如果要计算超过 32 位的数字，就要分多步骤进行。

4. 64 位CPU的计算性能一定比 32 位CPU高很多吗？

> 因为很少应用需要计算超过 32 位的数字，所以只有当计算超过 32 位的数，64 位的优势才能体现出来。





### 冯诺依曼模型

| 计算机基本结构    |                        |
| ----------------- | ---------------------- |
| 中央处理器( CPU ) | 控制器、运算器、寄存器 |
| 内存              |                        |
| 输入/输出设备     |                        |
| 总线              |                        |



### 中央处理器

Central Processing Unit，CPU

32位 和 64位 的 CPU 主要区别在于

- 32 位的 CPU 一次可以计算 4 个字节
- 64 位的 CPU 一次可以计算 8 个字节

这里的 32 位 和 64 位，就称为 CPU 的位宽。

CPU 的位宽表征的是 CPU 可以一次运算的数据量。



Q：为什么有了内存还需要寄存器？
原因是内存离CPU太远了，而寄存器就在CPU中，还紧挨着控制单元和逻辑运算单元，计算速度会更快。



### 程序执行的基本过程

1. CPU 读取 【程序计数器】 的值，这个值是指令的内存地址。然后，CPU 的【控制单元】操作【地址总线】指定要访问的内存地址，接着通知内存设备准备数据。数据准备好后通过【数据总线】将指令数据传给 CPU。CPU收到数据后，将指令存入【指令寄存器】。
2. CPU 分析【指令寄存器】中的指令，如果是计算类型的指令，就将指令交给【逻辑运算单元】运算，如果是存储类型的指令，则交给【控制单元】执行。
3. CPU 执行完指令后，【程序计数器】的值自增，表示指向下一条指令。



指令周期：CPU 从程序计数器（存储的是指令的内存地址）中读取指令、到执行的这个过程称为CPU的指令周期。

 

GHz，1GHz 表示 1s 产生 1G 次脉冲信号，时钟周期是 1/1G。一个高低电平就是一个时钟周期。

 ### 如何让程序跑的更快？

一个程序的CPU执行时间 = CPU时钟周期数 * 时钟周期时间

 

要想CPU跑得更快，可以提升主频。但是当性能达到瓶颈时，我们也可以减少程序所需的时钟周期数。

 时钟周期数 = 指令数 * 每条指令的平均时钟周期



想要程序跑得快，可以优化指令数：靠编译器



## 1.2 磁盘与内存

内存：断电后数据丢失

硬盘：断电后不会丢失

| 存储器层次结构                                               |                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| CPU中的寄存器                                                | 大脑正在思考的东西                                           |
| CPU Cache， CPU高速缓存<br /> 1. L1-Cache<br />2. L2-Cache <br />3. L3-Cache | 大脑中的记忆<br />L1 Cache 分为 数据缓存和指令缓存,是短期记忆<br />L2-Cache/L3-Cache是长期记忆 |
| 内存                                                         | 桌子上的书                                                   |
| 硬盘                                                         | 图书馆里的书                                                 |
|                                                              |                                                              |

注：绝大多数设计中，每个核心都有专属于自己的 L1 Cache 和 L2 Cache，而 L3 Cache 是多个CPU共享的。<span style="color:red;font-weight: bold;">那么多核心存在读写不一致的问题，如何解决呢？</span>

 

CPU Cache 用的是 SRAM（static random Access Memory，静态随机存储器），断电则数据丢失。

内存用的是 DRAM，动态随机存取寄存器，只需要一个晶体管和一个电容就能存储数据。因为数据被存储在电容中，而电容会漏电，因此需要定时刷新电容。

 

SSD 固态硬盘

HDD 机械硬盘

 

## 1.3 如何写出让CPU跑得更快的代码

 

### CPU Cache 的数据结构和读取过程

 

CPU Cache 是由很多个 Cache 行组成的，是CPU从内存读取数据的基本单位



一个内存的访问地址，包括 <span style="color:blue;font-weight:bold;">组标记、CPU Line索引、偏移量</span>

Cache Line 的构成 <span style="color:blue;font-weight:bold;">索引 + 有效位 + 组标记 + 数据块</span>

这里我们以简单的取模映射为例：

索引：找到对应的Cache-Line

组标记：因为取模后不同地址可能得到相同 Index，因此还需要组标记看看到底对不对

偏移量：行内偏移

 

如果 CPU 所要操作的数据在 CPU Cache 中，意味着缓存命中。缓存命中越高，代码的性能就越好。

 要想提升数据的缓存命中率，就按照内存布局顺序访问。

 

### CPU的分支预测器

 

如果分支预测可以预测到是执行`if`中的指令还是`else`中的指令，就可以提前把这些指令放到指令缓存中。这样CPU可以直接从 Cache 中读取指令，执行速度就会加快。

 

C/C++分支预测优化的宏

`__builtin_expect`( GCC 内置函数，提示编译器某条分支更可能执行)

 

 

C/C++编译器提供了`likely`和`unlikely`两种宏

宏定义

```c++
#define likely(x) __builtin_expect(!!(x), 1)
// !!(x)：将表达式转化为布尔值，告诉编译器x为真的概率很高
#define unlikely(x) __builtin_expect(!!(x), 0)
if (likely(a == 1)) {
	// do somthing...
} else {
	// do somthing...
}
```



### 如何提升多核CPU的缓存命中率？

 

如果一个线程都在同一个核心上执行，那么 L1 和 L2 Cache 的缓存命中率也会显著提高。





## 1.4 CPU缓存一致性

什么时候把 Cache 行中的 data 写回内存呢？

如何保证 Cache行 和内存数据的一致性？

- 写直达：把数据同时写入到Cache和内存中

    - 如果数据在 Cache 中，先把数据更新到 Cache 中，再写入到内存里面
    - 如果数据不在 Cache 中，就直接把数据更新到内存中

    缺点：每次都要写回到内存

- 写回：为了减少**将数据写回内存的频率**，

    - 当发生新的写操作时，数据仅仅被写入 Cache 行中，只有当 Cache 行中的数据要**被替换**时才会重新些人内存。




### 多个CPU核心如何解决缓存一致性问题

1. 当某个 CPU 核心中的 Cache 数据更新时，通知其他的 Cache，这叫做**写传播**
2. 某个 CP U核心对数据的操作顺序，在其他核心看来顺序是一样的，这叫做**事务的串行化**



解决方案：<span style="color:blue;">总线嗅探</span>

当 A 号 CPU 核心修改了 L1-Cache 中的 i 变量，就会通过【总线】将这个事件广播通知给其他核心。然后每个核心都会监听总线上的广播事件，并检查是否有相同的数据在自己的 L1-Cache 里面。

如果 B 号 CPU 核心的 L1-Cache 中有该数据，那么需要把该数据更新到自己的 L1-Cache

缺点：总线嗅探不能保证**事务的串行化**，而且总线压力很大。

#### 基于总线嗅探和状态机的 MESI 协议

`Modified`

`Exclusive`

`Shared`

`Invalidate`

## 1.5 CPU 是如何执行任务的？

### CPU伪共享问题

多个线程同时读写同一个 Cache 行的不同变量时，导致 Cache 行的作用失效，需要频繁写入内存的现象。



Q：如何避免伪共享问题？

在 Linux 内核中，如果是多核 (MP) 系统，有一个宏定义叫做`__Cacheline_aligned`，是 Cache-line 的大小。



### CPU如何选择线程

在 Linux 系统中，无论是 线程 还是 进程 对应到内核中，都是用`task_struct`表示的。

| 任务分类 | 优先级  |
| -------- | ------- |
| 实时任务 | 0~99    |
| 普通任务 | 100~139 |

值越低，优先级越高。

## 1.6 中断

中断处理的程序应该尽量短且快。



Linux系统为了解决中断处理程序**执行过长**和**中断丢失**的问题，将中断过程分为两个部分。

上半部分（也叫硬中断）会快速处理中断，期间关闭中断请求；

下半部分一般以内核线程（也叫软中断）的方式继续处理上半部分未完成的工作。



每个 CPU 都对应一个软中断内核线程，名称一般为 `ksoftirqd/CPU 编号`

```shell
# 查看软中断的运行情况
cat /proc/softirqs
# 查看硬中断的运行情况
cat /proc/interrupts
```

![image-20251126113245498](E:\Note\03 操作系统\OperatingSystem.assets\image-20251126113245498.png)

```shell
watch -d 'awk "NR>1 {printf \"%-12s %8s %8s\\n\", \$1, \$2, \$3}" /proc/softirqs'
# 查看中断次数的变化速率 -d 高亮变化的字段
```

软中断是以内核线程的方式执行的，

```shell
ps aux | grep softirq
# ps process status 查看当前正在运行的进程状态
# a 显示所有用户的进程
# u 以用户友好的格式显示
# x 显示无终端的进程，如守护进程
```

![image-20251126114630169](E:\Note\03 操作系统\OperatingSystem.assets\image-20251126114630169.png)



### 如何定位软中断 CPU 使用率过高的问题？







# 内存管理



 
